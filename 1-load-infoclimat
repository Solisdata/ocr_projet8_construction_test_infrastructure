# load_meteo_data_mongodb.py

import json
import boto3
from pymongo import MongoClient
from datetime import datetime



# CONFIGURATION CONNEXION SOURCE S3

BUCKET_NAME = "ocr-projet8"
s3_prefix = "raw_meteo_data/meteo_dataset/"

# fonction pour prendre le dernier fichier chargé dans le bucket
def get_latest_s3_key(bucket_name, prefix):
    s3 = boto3.client("s3")

    response = s3.list_objects_v2(
        Bucket=bucket_name,
        Prefix=prefix
    )

    if "Contents" not in response:
        raise ValueError(f"Aucun fichier trouvé dans {prefix}")

    latest_object = max(
        response["Contents"],
        key=lambda x: x["LastModified"]
    )

    print(f"✓ Dernier fichier détecté : {latest_object['Key']}")
    return latest_object["Key"]

s3_key = get_latest_s3_key(BUCKET_NAME, s3_prefix)

# je charge le fichier
def load_s3_jsonl(bucket_name, key):
    s3 = boto3.client("s3")
    response = s3.get_object(Bucket=bucket_name, Key=key)
    lines = response["Body"].read().decode("utf-8").splitlines()

    records = [json.loads(line) for line in lines]
    print(f"✓ {len(records)} lignes JSONL chargées")
    return records

df = load_s3_jsonl(BUCKET_NAME, s3_key)
#j'observe les clés
print("type fichier:",type(df))

#j'extrait les la partie qui m'interessent qui se trouvent dans airbyte_date
meteo_data = [row["_airbyte_data"] for row in df]
print("type fichier info météo", type(meteo_data))
print("clés meteo_data", meteo_data[0].keys())

#j'extrait les données qui m'interessent (metadata, stations et hourly)
stations = [] #liste de dictionnaires : description des stations
hourly_list = [] #dictionnaire de listes par stations --> transformé en liste de dictionnaires
metadata = {} # dictionnaire unique : 

for i in meteo_data:
    # Stations
    stations.extend(i.get("stations", [])) #Pour chaque liste du JSON, on prend les dictionnaires qui sont dans stations quand on trouve la clé stations
    
    # Hourly
    hourly_dict = i.get("hourly", {})
    for station_id, measures in hourly_dict.items():
        if station_id == "_params":  # ignorer les paramètres généraux
            continue
        for measure in measures:
            # Ajouter l'id de la station à chaque mesure
            # measure["station_id"] = station_id
            hourly_list.append(measure)
        #on parcourt toutes les stations dans hourly  et on accumule toutes les mesures dans une liste globale en on ajoute l’identifiant de la station à chaque mesure,

    # Metadata
    metadata = i.get("metadata", {})

print("clé stations:", stations[0].keys())
print(f"✓ Nombre de lignes stations chargées : {len(stations)}") 
print("clé hourly:", hourly_list[0].keys())
print(f"✓ Nombre de lignes horaires chargées : {len(hourly_list)}") 



#Modifications des données 

def remove_duplicates(records, unique_fields):
    # Crée un dictionnaire avec pour clé le tuple des champs uniques
    cleaned_dict = {tuple(record[f] for f in unique_fields): record for record in records}
    
    # Convertit les valeurs du dictionnaire en liste
    cleaned_list = list(cleaned_dict.values())
    
    print(f"✓ Total lignes avant suppression : {len(records)}")
    print(f"✓ Total lignes après suppression : {len(cleaned_list)}")
    print(f"✓ Doublons supprimés : {len(records) - len(cleaned_list)}")
    
    return cleaned_list

# Suppression des doublons dans hourly_list
hourly_list = remove_duplicates(hourly_list, ["id_station", "dh_utc"])

# Pour les stations
stations = remove_duplicates(stations, ["id"])


#pour les données horaires 
from datetime import datetime

def clean_and_prepare_hourly(hourly_list):
    """
    # récupérer la température, None si pas de valeur ou mauvaise : faire pour les autres valeurs
    
    """
    cleaned_list = []
    for h in hourly_list:
        # récupérer la température, None si pas de valeur ou mauvaise
        try:
            temperature_value = float(h.get("temperature", None))
        except (ValueError, TypeError):
            temperature_value = None

        # Vérification température
        if temperature_value is None or -50 <= temperature_value <= 50:
            cleaned_list.append(h)  # garder la ligne même si temp manquante
        else:
            print(f"⚠️ Temperature aberrante supprimée : {h['id_station']} {h.get('dh_utc')} = {temperature_value}")

    print(f"✓ Lignes initiales : {len(hourly_list)}")
    print(f"✓ Lignes après cleaning : {len(cleaned_list)}")

    return cleaned_list


clean_and_prepare_hourly(hourly_list)


##AJOUTER LA NORMALISATION POUR LES AUTRES STATIONS



# INSERTION DANS MONGODB

# CONFIGURATION  CONNEXION MONGODB

MONGO_URI = "mongodb://localhost:27017/"
DB_NAME  = "meteo_db"

# CONNEXION MONGO

def get_mongodb_collections():
    client = MongoClient(MONGO_URI)
    db = client[DB_NAME]
    print("Connexion à MongoDB établie.")
    return db["stations"], db["metadata"], db["hourly"]



# Collections
stations_col, metadata_col, hourly_col = get_mongodb_collections()


# ----------------------------
# Index uniques pour éviter doublons
# ----------------------------
stations_col.create_index("id", unique=True)
hourly_col.create_index([("id_station", 1), ("dh_utc", 1)], unique=True)
# metadata : pas d'index unique nécessaire ici (un seul document)

# ----------------------------
# Insertion stations
# ----------------------------
if stations:
    result = stations_col.insert_many(stations)
    print(f"✓ {len(result.inserted_ids)} stations insérées")

# ----------------------------
# Insertion metadata
# ----------------------------
if metadata:
    # metadata est un dict, on le transforme en liste de dict avec _id si nécessaire
    metadata_doc = metadata.copy()  # pour ne pas modifier l'original
    metadata_col.insert_one(metadata_doc)
    print(f"✓ Metadata insérée")

# ----------------------------
# Insertion hourly
# ----------------------------
if hourly_list:
    result = hourly_col.insert_many(hourly_list)
    print(f"✓ {len(result.inserted_ids)} mesures horaires insérées")



'''
si je veux dans une seule collection  : 
combined_list = []

for h in hourly_list:
    # trouver la station correspondante
    station = next((s for s in stations if s["id"] == h["id_station"]), {})
    
    # construire un document unique
    doc = {
        "id_station": h["id_station"],
        "dh_utc": h["dh_utc"],
        "temperature": h.get("temperature"),
        "pression": h.get("pression"),
        "humidite": h.get("humidite"),
        "point_de_rosee": h.get("point_de_rosee"),
        "visibilite": h.get("visibilite"),
        "vent_moyen": h.get("vent_moyen"),
        "vent_rafales": h.get("vent_rafales"),
        "vent_direction": h.get("vent_direction"),
        "pluie_3h": h.get("pluie_3h"),
        "pluie_1h": h.get("pluie_1h"),
        "neige_au_sol": h.get("neige_au_sol"),
        "nebulosite": h.get("nebulosite"),
        "temps_omm": h.get("temps_omm"),
        # infos station imbriquées
        "station": station,
        # metadata complet imbriqué
        "metadata": metadata
    }
    combined_list.append(doc)

'''